{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrender\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import optimize\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.data.iphone import IPhoneDataLoader\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, SimpleImageRenderer, setup_standard_scene, get_perspective_camera, backproject_image\n",
    "from face_reconstruction.optim import BFMOptimization, run_icp, NearestNeighborMode, DistanceType, nearest_neighbors\n",
    "from face_reconstruction.utils.math import add_column, geometric_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-organic",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-congress",
   "metadata": {},
   "source": [
    "# 2. Input RGB-D Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "frame_id = 4\n",
    "\n",
    "#loader = BiwiDataLoader(run_id)\n",
    "loader = IPhoneDataLoader()\n",
    "\n",
    "frame = loader.get_frame(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.get_color_image()\n",
    "depth_img = frame.get_depth_image()\n",
    "img_width = loader.get_image_width()\n",
    "img_height = loader.get_image_height()\n",
    "intrinsics = frame.get_intrinsics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    depth_threshold = 0.5 # Drop all points behind that threshold\n",
    "    \n",
    "    intrinsics = frame.get_intrinsics()\n",
    "    points = backproject_image(intrinsics, depth_img)\n",
    "    points_to_render = points[:, :3]\n",
    "    points_to_render *= 1000 # meter to millimeter\n",
    "    colors = img.reshape(-1, 3)  # Just flatten color image\n",
    "    \n",
    "    foreground_mask = depth_img.reshape(-1) < depth_threshold\n",
    "    pointcloud = points_to_render[foreground_mask]\n",
    "    colors = colors[foreground_mask]\n",
    "else:\n",
    "    # Registration\n",
    "    pointcloud, colors, screen_positions = register_rgb_depth(frame.get_depth_image(), frame.get_color_image(), biwi_loader.get_depth_intrinsics(), biwi_loader.get_rgb_intrinsics(), biwi_loader.get_rgb_extrinsics())\n",
    "pointcloud[:, 2] = -pointcloud[:, 2]  # Invert z-coordinate for easier rendering (point cloud will be right in front of camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-springfield",
   "metadata": {},
   "source": [
    "# 3. Detect 3D Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_img, face_pos = detect_landmarks(img, return_face_pos=True)\n",
    "face_pos = face_pos[0] # Assume there is only one face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a depth image for easier querying of depth values\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    rgb_depth_img = depth_img\n",
    "else:\n",
    "    rgb_depth_img = np.zeros((img_height, img_width))\n",
    "    for point, screen_position in zip(pointcloud, screen_positions):\n",
    "        rgb_depth_img[screen_position[1], screen_position[0]] = -point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As RGB and depth channels are not aligned, we might not have exact depth information for every pixel in the color channel. Hence, we have to interpolate\n",
    "interpolation_size = 1\n",
    "rgb_depth_values = [interpolate_around(rgb_depth_img, pixel, interpolation_size) for pixel in landmarks_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d = backproject_points(intrinsics, rgb_depth_values, landmarks_img)\n",
    "landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    landmark_points_3d_render *= 1000  # meter to millimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d_median = geometric_median(landmark_points_3d_render)\n",
    "distances_from_median = np.linalg.norm(landmark_points_3d_render - landmark_points_3d_median, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_landmark_deviation = 500  # It can happen that depth information is bad and back-projected landmark points are far away from the other. These should be ignored\n",
    "valid_landmark_points_3d = np.where((np.array(rgb_depth_values) != 0) & (distances_from_median < threshold_landmark_deviation))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_without_depth = 68 - len(valid_landmark_points_3d)\n",
    "if pixels_without_depth > 0:\n",
    "    print(f\"There are {pixels_without_depth} pixels without depth information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-cincinnati",
   "metadata": {},
   "source": [
    "## 3.1 Restrict Pointcloud to Facial Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_depth_values = []\n",
    "face_pixels = []\n",
    "for x in range(face_pos.left(), face_pos.right() + 1):\n",
    "    for y in range(face_pos.top(), face_pos.bottom() + 1):\n",
    "        pixel = [x, y]\n",
    "        face_depth_value = interpolate_around(rgb_depth_img, pixel, interpolation_size)\n",
    "        if face_depth_value > 0:\n",
    "            face_depth_values.append(face_depth_value)\n",
    "            face_pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pointcloud = backproject_points(intrinsics, face_depth_values, face_pixels)\n",
    "face_pointcloud[:, 2] = -face_pointcloud[:, 2]\n",
    "face_pointcloud_colors = np.array([img[y, x] for x, y in face_pixels])\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    face_pointcloud *= 1000  # Meters to Millimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_depth_values = []\n",
    "body_pixels = []\n",
    "for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "        if (x < face_pos.left() or x > face_pos.right()) or (y < face_pos.top() or y > face_pos.bottom()):\n",
    "            pixel = [x, y]\n",
    "            body_depth_value = interpolate_around(rgb_depth_img, pixel, interpolation_size)\n",
    "            if body_depth_value > 0:\n",
    "                body_depth_values.append(body_depth_value)\n",
    "                body_pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_pointcloud = backproject_points(intrinsics, body_depth_values, body_pixels)\n",
    "body_pointcloud[:, 2] = -body_pointcloud[:, 2]\n",
    "body_pointcloud_colors = np.array([img[y, x] for x, y in body_pixels])\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    body_pointcloud *= 1000  # Meters to Millimeters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-definition",
   "metadata": {},
   "source": [
    "# 4. ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-drill",
   "metadata": {},
   "source": [
    "## 4.1 Sparse Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_sparse = 3 # 20\n",
    "n_params_expression_sparse = 3 # 10\n",
    "weight_shape_params_sparse = 100 # 10000\n",
    "weight_expression_params_sparse = 100 # 1000\n",
    "l2_regularization_sparse = 10000  # regularizes only face model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_sparse,\n",
    "                               n_params_expression=n_params_expression_sparse, \n",
    "                               weight_shape_params=weight_shape_params_sparse, \n",
    "                               weight_expression_params=weight_expression_params_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_camera_pose = np.eye(4) # position camera just in front of face\n",
    "initial_params = sparse_optimizer.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_loss = sparse_optimizer.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d], regularization_strength=l2_regularization_sparse)\n",
    "sparse_context = sparse_optimizer.create_optimization_context(sparse_loss, initial_params)\n",
    "result = sparse_context.run_optimization(sparse_loss, initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sparse = sparse_context.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-nicholas",
   "metadata": {},
   "source": [
    "## 4.2 Dense Reconstruction with ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mode = NearestNeighborMode.FACE_VERTICES # FACE_VERTICES: every face vertex will be assigned its nearest neighbor in pointcloud\n",
    "                                            # POINTCLOUD: every point in pointcloud will be assigned its nearest neighbor in face model\n",
    "distance_type = DistanceType.POINT_TO_POINT\n",
    "icp_iterations = 2\n",
    "optimization_steps_per_iteration = 20\n",
    "l2_regularization_dense = 100 # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_dense = 20 # 20\n",
    "n_params_expression_dense = 20 # 10\n",
    "weight_shape_params_dense = 100 # 10000\n",
    "weight_expression_params_dense = 100 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_dense,\n",
    "                               n_params_expression=n_params_expression_dense, \n",
    "                               weight_shape_params=weight_shape_params_dense, \n",
    "                               weight_expression_params=weight_expression_params_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, distances, _ = run_icp(dense_optimizer, \n",
    "                               face_pointcloud,\n",
    "                               bfm, \n",
    "                               params_sparse.with_new_manager(dense_optimizer), \n",
    "                               max_iterations=icp_iterations, \n",
    "                               nearest_neighbor_mode=nn_mode, \n",
    "                               distance_type=distance_type,\n",
    "                               max_nfev=optimization_steps_per_iteration,\n",
    "                               l2_regularization=l2_regularization_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-channels",
   "metadata": {},
   "source": [
    "# 5. Render Face Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_render = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params_render.shape_coefficients, \n",
    "        expression_coefficients=params_render.expression_coefficients, \n",
    "        color_coefficients=params_render.color_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(show_pointcloud=True, show_mask=True, show_pointcloud_face=False, cut_around_face=4):\n",
    "    bfm_vertices = params_render.camera_pose @ add_column(face_mesh.vertices, 1).T\n",
    "    distances, indices = nearest_neighbors(pointcloud, bfm_vertices[:3, :].T)\n",
    "    pointcloud_mask = distances > cut_around_face\n",
    "    \n",
    "    perspective_camera = get_perspective_camera(intrinsics, img_width, img_height)\n",
    "    scene = setup_standard_scene(perspective_camera)\n",
    "    if show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(pointcloud[pointcloud_mask], colors=colors[pointcloud_mask]), pose=initial_camera_pose)\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params_render.camera_pose)\n",
    "    if not show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(face_pointcloud, colors=face_pointcloud_colors), pose=initial_camera_pose)\n",
    "    if show_pointcloud and not show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(body_pointcloud, colors=body_pointcloud_colors), pose=initial_camera_pose)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-pizza",
   "metadata": {},
   "source": [
    "## 5.1. Interactive 3D Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_pointcloud=True, show_mask=True, show_pointcloud_face=True, cut_around_face=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-offer",
   "metadata": {},
   "source": [
    "## 5.2. Render mask onto Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_pointcloud=False, show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "r.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_mask = np.array(img)\n",
    "img_with_mask[depth != 0] = color[depth != 0]\n",
    "plt.imshow(img_with_mask)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
