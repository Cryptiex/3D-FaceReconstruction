{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrender\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import optimize\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, SimpleImageRenderer\n",
    "from face_reconstruction.optim import BFMOptimization, run_icp, NearestNeighborMode, DistanceType, nearest_neighbors\n",
    "from face_reconstruction.utils.math import add_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-insight",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-attempt",
   "metadata": {},
   "source": [
    "# 2. Input RGB-D Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "frame_id = 4\n",
    "\n",
    "biwi_loader = BiwiDataLoader(run_id)\n",
    "frame = biwi_loader.get_frame(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.get_color_image()\n",
    "img_width = biwi_loader.get_image_width()\n",
    "img_height = biwi_loader.get_image_height()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registration\n",
    "pointcloud, colors, screen_positions = register_rgb_depth(frame.get_depth_image(), frame.get_color_image(), biwi_loader.get_depth_intrinsics(), biwi_loader.get_rgb_intrinsics(), biwi_loader.get_rgb_extrinsics())\n",
    "pointcloud[:, 2] = -pointcloud[:, 2]  # Invert z-coordinate for easier rendering (point cloud will be right in front of camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-norwegian",
   "metadata": {},
   "source": [
    "# 3. Detect 3D Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_img, face_pos = detect_landmarks(img, return_face_pos=True)\n",
    "face_pos = face_pos[0] # Assume there is only one face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a depth image for easier querying of depth values\n",
    "rgb_depth_img = np.zeros((img_height, img_width))\n",
    "for point, screen_position in zip(pointcloud, screen_positions):\n",
    "    rgb_depth_img[screen_position[1], screen_position[0]] = -point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As RGB and depth channels are not aligned, we might not have exact depth information for every pixel in the color channel. Hence, we have to interpolate\n",
    "interpolation_size = 1\n",
    "rgb_depth_values = [interpolate_around(rgb_depth_img, pixel, interpolation_size) for pixel in landmarks_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_without_depth = sum(np.array(rgb_depth_values) == 0)\n",
    "if pixels_without_depth > 0:\n",
    "    print(f\"There are {pixels_without_depth} pixels without depth information. Consider increasing `interpolation_size`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_landmark_points_3d = np.where(np.array(rgb_depth_values) != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d = backproject_points(biwi_loader.get_rgb_intrinsics(), rgb_depth_values, landmarks_img)\n",
    "landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-violin",
   "metadata": {},
   "source": [
    "## 3.1 Restrict Pointcloud to Facial Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_depth_values = []\n",
    "face_pixels = []\n",
    "for x in range(face_pos.left(), face_pos.right() + 1):\n",
    "    for y in range(face_pos.top(), face_pos.bottom() + 1):\n",
    "        pixel = [x, y]\n",
    "        face_depth_value = interpolate_around(rgb_depth_img, pixel, interpolation_size)\n",
    "        if face_depth_value > 0:\n",
    "            face_depth_values.append(face_depth_value)\n",
    "            face_pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pointcloud = backproject_points(biwi_loader.get_rgb_intrinsics(), face_depth_values, face_pixels)\n",
    "face_pointcloud[:, 2] = -face_pointcloud[:, 2]\n",
    "face_pointcloud_colors = np.array([img[y, x] for x, y in face_pixels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_depth_values = []\n",
    "body_pixels = []\n",
    "for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "        if (x < face_pos.left() or x > face_pos.right()) or (y < face_pos.top() or y > face_pos.bottom()):\n",
    "            pixel = [x, y]\n",
    "            body_depth_value = interpolate_around(rgb_depth_img, pixel, interpolation_size)\n",
    "            if body_depth_value > 0:\n",
    "                body_depth_values.append(body_depth_value)\n",
    "                body_pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_pointcloud = backproject_points(biwi_loader.get_rgb_intrinsics(), body_depth_values, body_pixels)\n",
    "body_pointcloud[:, 2] = -body_pointcloud[:, 2]\n",
    "body_pointcloud_colors = np.array([img[y, x] for x, y in body_pixels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-soundtrack",
   "metadata": {},
   "source": [
    "# 4. ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-internship",
   "metadata": {},
   "source": [
    "## 4.1 Setup Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape = 20 # 20\n",
    "n_params_expression = 20 # 10\n",
    "weight_shape_params = 100 # 10000\n",
    "weight_expression_params = 100 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape,\n",
    "                               n_params_expression=n_params_expression, \n",
    "                               weight_shape_params=weight_shape_params, \n",
    "                               weight_expression_params=weight_expression_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_camera_pose = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]) # position camera just in front of face\n",
    "initial_params = optimizer.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-feedback",
   "metadata": {},
   "source": [
    "## 4.2 Sparse Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_regularization_sparse = 10000  # regularizes only face model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_loss = optimizer.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d], regularization_strength=l2_regularization_sparse)\n",
    "result = optimizer.run_optimization(sparse_loss, initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sparse = optimizer.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-mason",
   "metadata": {},
   "source": [
    "## 4.3 Dense Reconstruction with ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mode = NearestNeighborMode.FACE_VERTICES # FACE_VERTICES: every face vertex will be assigned its nearest neighbor in pointcloud\n",
    "                                            # POINTCLOUD: every point in pointcloud will be assigned its nearest neighbor in face model\n",
    "distance_type = DistanceType.POINT_TO_POINT\n",
    "icp_iterations = 5\n",
    "optimization_steps_per_iteration = 20\n",
    "l2_regularization_dense = 100 # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, distances, _ = run_icp(optimizer, \n",
    "                               face_pointcloud,\n",
    "                               bfm, \n",
    "                               params_sparse, \n",
    "                               max_iterations=icp_iterations, \n",
    "                               nearest_neighbor_mode=nn_mode, \n",
    "                               distance_type=distance_type,\n",
    "                               max_nfev=optimization_steps_per_iteration,\n",
    "                               l2_regularization=l2_regularization_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-orleans",
   "metadata": {},
   "source": [
    "# 5. Render Face Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_render = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params_render.shape_coefficients, \n",
    "        expression_coefficients=params_render.expression_coefficients, \n",
    "        color_coefficients=params_render.color_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(show_pointcloud=True, show_mask=True, show_pointcloud_face=False, cut_around_face=4):\n",
    "    bfm_vertices = params_render.camera_pose @ add_column(face_mesh.vertices, 1).T\n",
    "    distances, indices = nearest_neighbors(pointcloud, bfm_vertices[:3, :].T)\n",
    "    pointcloud_mask = distances > cut_around_face\n",
    "    \n",
    "    \n",
    "    perspective_camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "    directional_light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
    "    scene = pyrender.Scene()\n",
    "    if show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(pointcloud[pointcloud_mask], colors=colors[pointcloud_mask]), pose=initial_camera_pose)\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params_render.camera_pose)\n",
    "    if not show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(face_pointcloud, colors=face_pointcloud_colors), pose=initial_camera_pose)\n",
    "    if show_pointcloud and not show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(body_pointcloud, colors=body_pointcloud_colors), pose=initial_camera_pose)\n",
    "    scene.add(perspective_camera)\n",
    "    scene.add(directional_light)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_pointcloud=True, show_mask=True, show_pointcloud_face=True, cut_around_face=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "r.delete()\n",
    "plt.imshow(color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
