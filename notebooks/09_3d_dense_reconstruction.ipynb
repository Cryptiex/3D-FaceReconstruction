{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrender\n",
    "import open3d\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import optimize\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.data.iphone import IPhoneDataLoader\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, SimpleImageRenderer, setup_standard_scene, get_perspective_camera, backproject_image\n",
    "from face_reconstruction.optim import BFMOptimization, run_icp, NearestNeighborMode, DistanceType, nearest_neighbors, run_icp_combined\n",
    "from face_reconstruction.utils.math import add_column, geometric_median\n",
    "from face_reconstruction.plots import PlotManager, plot_reconstruction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-cholesterol",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-portrait",
   "metadata": {},
   "source": [
    "# 2. Input RGB-D Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "frame_id = 36\n",
    "\n",
    "#loader = BiwiDataLoader(run_id)\n",
    "loader = IPhoneDataLoader()\n",
    "\n",
    "frame = loader.get_frame(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.get_color_image()\n",
    "depth_img = frame.get_depth_image()\n",
    "img_width = loader.get_image_width()\n",
    "img_height = loader.get_image_height()\n",
    "intrinsics = frame.get_intrinsics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    depth_threshold = 0.5 # Drop all points behind that threshold\n",
    "    \n",
    "    intrinsics = frame.get_intrinsics()\n",
    "    points = backproject_image(intrinsics, depth_img)\n",
    "    points_to_render = points[:, :3]\n",
    "    points_to_render *= 1000 # meter to millimeter\n",
    "    colors = img.reshape(-1, 3)  # Just flatten color image\n",
    "    \n",
    "    foreground_mask = depth_img.reshape(-1) < depth_threshold\n",
    "    pointcloud = points_to_render[foreground_mask]\n",
    "    colors = colors[foreground_mask]\n",
    "else:\n",
    "    # Registration\n",
    "    pointcloud, colors, screen_positions = register_rgb_depth(frame.get_depth_image(), frame.get_color_image(), biwi_loader.get_depth_intrinsics(), biwi_loader.get_rgb_intrinsics(), biwi_loader.get_rgb_extrinsics())\n",
    "pointcloud[:, 2] = -pointcloud[:, 2]  # Invert z-coordinate for easier rendering (point cloud will be right in front of camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-neighborhood",
   "metadata": {},
   "source": [
    "## 2.1. Compute Normals of Pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = open3d.geometry.PointCloud(points=open3d.utility.Vector3dVector(pointcloud))\n",
    "pc.estimate_normals()\n",
    "pointcloud_normals = np.asarray(pc.normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-spirit",
   "metadata": {},
   "source": [
    "# 3. Detect 3D Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_img, face_pos = detect_landmarks(img, return_face_pos=True)\n",
    "face_pos = face_pos[0] # Assume there is only one face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a depth image for easier querying of depth values\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    rgb_depth_img = depth_img\n",
    "else:\n",
    "    rgb_depth_img = np.zeros((img_height, img_width))\n",
    "    for point, screen_position in zip(pointcloud, screen_positions):\n",
    "        rgb_depth_img[screen_position[1], screen_position[0]] = -point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As RGB and depth channels are not aligned, we might not have exact depth information for every pixel in the color channel. Hence, we have to interpolate\n",
    "interpolation_size = 1\n",
    "rgb_depth_values = [interpolate_around(rgb_depth_img, pixel, interpolation_size) for pixel in landmarks_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d = backproject_points(intrinsics, rgb_depth_values, landmarks_img)\n",
    "landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    landmark_points_3d_render *= 1000  # meter to millimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d_median = geometric_median(landmark_points_3d_render)\n",
    "distances_from_median = np.linalg.norm(landmark_points_3d_render - landmark_points_3d_median, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_landmark_deviation = 500  # It can happen that depth information is bad and back-projected landmark points are far away from the other. These should be ignored\n",
    "valid_landmark_points_3d = np.where((np.array(rgb_depth_values) != 0) & (distances_from_median < threshold_landmark_deviation))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_without_depth = 68 - len(valid_landmark_points_3d)\n",
    "if pixels_without_depth > 0:\n",
    "    print(f\"There are {pixels_without_depth} pixels without depth information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-company",
   "metadata": {},
   "source": [
    "## 3.1 Restrict Pointcloud to Facial Points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_depth_values = []\n",
    "face_pixels = []\n",
    "for x in range(face_pos.left(), face_pos.right() + 1):\n",
    "    for y in range(face_pos.top(), face_pos.bottom() + 1):\n",
    "        pixel = [x, y]\n",
    "        face_depth_value = interpolate_around(rgb_depth_img, pixel, interpolation_size)\n",
    "        if face_depth_value > 0:\n",
    "            face_depth_values.append(face_depth_value)\n",
    "            face_pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_pointcloud = backproject_points(intrinsics, face_depth_values, face_pixels)\n",
    "face_pointcloud[:, 2] = -face_pointcloud[:, 2]\n",
    "face_pointcloud_colors = np.array([img[y, x] for x, y in face_pixels])\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    face_pointcloud *= 1000  # Meters to Millimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_depth_values = []\n",
    "body_pixels = []\n",
    "for x in range(img_width):\n",
    "    for y in range(img_height):\n",
    "        if (x < face_pos.left() or x > face_pos.right()) or (y < face_pos.top() or y > face_pos.bottom()):\n",
    "            pixel = [x, y]\n",
    "            body_depth_value = interpolate_around(rgb_depth_img, pixel, interpolation_size)\n",
    "            if body_depth_value > 0:\n",
    "                body_depth_values.append(body_depth_value)\n",
    "                body_pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_pointcloud = backproject_points(intrinsics, body_depth_values, body_pixels)\n",
    "body_pointcloud[:, 2] = -body_pointcloud[:, 2]\n",
    "body_pointcloud_colors = np.array([img[y, x] for x, y in body_pixels])\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    body_pointcloud *= 1000  # Meters to Millimeters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-scout",
   "metadata": {},
   "source": [
    "# 4. ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-missile",
   "metadata": {},
   "source": [
    "## 4.1 Sparse Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_sparse = 3 # 20\n",
    "n_params_expression_sparse = 3 # 10\n",
    "weight_shape_params_sparse = 100 # 10000\n",
    "weight_expression_params_sparse = 100 # 1000\n",
    "l2_regularization_sparse = 10000  # regularizes only face model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_sparse,\n",
    "                               n_params_expression=n_params_expression_sparse, \n",
    "                               weight_shape_params=weight_shape_params_sparse, \n",
    "                               weight_expression_params=weight_expression_params_sparse,\n",
    "                               rotation_mode='lie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "from numpy.linalg import det\n",
    "\n",
    "initial_camera_pose = np.eye(4)\n",
    "initial_camera_pose[2, 3] = -100  # position face already on pointcloud\n",
    "\n",
    "if sparse_optimizer.rotation_mode == 'lie':\n",
    "    theta = 0.0001\n",
    "    initial_camera_pose[:3, :3] = np.array([[1, 0, 0], [0, cos(theta), -sin(theta)], [0, sin(theta), cos(theta)]])\n",
    "    assert abs(det(initial_camera_pose) - 1.0) < 0.00001 \n",
    "\n",
    "initial_params = sparse_optimizer.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_loss = sparse_optimizer.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d], regularization_strength=l2_regularization_sparse)\n",
    "sparse_context = sparse_optimizer.create_optimization_context(sparse_loss, initial_params)\n",
    "result = sparse_context.run_optimization(sparse_loss, initial_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (sparse_context.create_parameters_from_theta(initial_params.to_theta()).camera_pose - initial_params.camera_pose < 1e-8).all(), \"OptimizationParameters is ill-defined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sparse = sparse_context.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-declaration",
   "metadata": {},
   "source": [
    "## 4.2 Dense Reconstruction with ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mode = NearestNeighborMode.FACE_VERTICES # FACE_VERTICES: every face vertex will be assigned its nearest neighbor in pointcloud\n",
    "                                            # POINTCLOUD: every point in pointcloud will be assigned its nearest neighbor in face model\n",
    "distance_type = DistanceType.POINT_TO_POINT\n",
    "icp_iterations = 5\n",
    "optimization_steps_per_iteration = 15\n",
    "l2_regularization_dense = 100 # 10000 for Lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_dense = 30 # 20\n",
    "n_params_expression_dense = 30 # 10\n",
    "weight_shape_params_dense = 100 # 10000, 10000000000 for POINT_TO_PLANE\n",
    "weight_expression_params_dense = 100 # 1000, 10000000000 for POINT_TO_PLANE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_dense,\n",
    "                               n_params_expression=n_params_expression_dense, \n",
    "                               weight_shape_params=weight_shape_params_dense, \n",
    "                               weight_expression_params=weight_expression_params_dense,\n",
    "                               rotation_mode='lie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, distances, dense_param_history, dense_cost_history = run_icp(dense_optimizer, \n",
    "                               face_pointcloud,\n",
    "                               bfm, \n",
    "                               params_sparse.with_new_manager(dense_optimizer), \n",
    "                               max_iterations=icp_iterations, \n",
    "                               nearest_neighbor_mode=nn_mode, \n",
    "                               distance_type=distance_type,\n",
    "                               max_nfev=optimization_steps_per_iteration,\n",
    "                               l2_regularization=l2_regularization_dense,\n",
    "                              pointcloud_normals=pointcloud_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sparse_term = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_combined, distances, dense_param_history = run_icp_combined(dense_optimizer, \n",
    "                                                                  bfm_landmark_indices[valid_landmark_points_3d], \n",
    "                                                                  landmark_points_3d_render[valid_landmark_points_3d],\n",
    "                                                                  face_pointcloud,\n",
    "                                                                  bfm,\n",
    "                                                                  params_sparse.with_new_manager(dense_optimizer),\n",
    "                                                                  max_iterations=icp_iterations, \n",
    "                                                                  nearest_neighbor_mode=nn_mode, \n",
    "                                                                  distance_type=distance_type,\n",
    "                                                                  weight_sparse_term=weight_sparse_term,\n",
    "                                                                  max_nfev=optimization_steps_per_iteration,\n",
    "                                                                  l2_regularization=l2_regularization_dense,\n",
    "                                                                  pointcloud_normals=pointcloud_normals)                              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-humanitarian",
   "metadata": {},
   "source": [
    "# 5. Render Face Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_render = params_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params_render.shape_coefficients, \n",
    "        expression_coefficients=params_render.expression_coefficients, \n",
    "        color_coefficients=params_render.color_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(show_pointcloud=True, show_mask=True, show_pointcloud_face=False, cut_around_face=4):\n",
    "    bfm_vertices = params_render.camera_pose @ add_column(face_mesh.vertices, 1).T\n",
    "    distances, indices = nearest_neighbors(pointcloud, bfm_vertices[:3, :].T)\n",
    "    pointcloud_mask = distances > cut_around_face\n",
    "    \n",
    "    perspective_camera = get_perspective_camera(intrinsics, img_width, img_height)\n",
    "    scene = setup_standard_scene(perspective_camera)\n",
    "    if show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(pointcloud[pointcloud_mask], colors=colors[pointcloud_mask]))\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params_render.camera_pose)\n",
    "    if not show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(face_pointcloud, colors=face_pointcloud_colors))\n",
    "    if show_pointcloud and not show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(body_pointcloud, colors=body_pointcloud_colors))\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-observer",
   "metadata": {},
   "source": [
    "## 5.1. Interactive 3D Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_pointcloud=True, show_mask=True, show_pointcloud_face=True, cut_around_face=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-working",
   "metadata": {},
   "source": [
    "## 5.2. Render mask onto Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_pointcloud=False, show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "r.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_mask = np.array(img)\n",
    "img_with_mask[depth != 0] = color[depth != 0]\n",
    "plt.imshow(img_with_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-fifth",
   "metadata": {},
   "source": [
    "# 6. Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_param_history(plot_manager, param_history):\n",
    "    for i, params in enumerate(param_history):\n",
    "        face_mesh = bfm.draw_sample(\n",
    "                shape_coefficients=params.shape_coefficients,\n",
    "                expression_coefficients=params.expression_coefficients,\n",
    "                color_coefficients=[0 for _ in range(n_color_coefficients)])\n",
    "        translation = np.zeros((4, 4))\n",
    "        translation[2, 3] = -150\n",
    "\n",
    "        perspective_camera = get_perspective_camera(intrinsics, img_width, img_height)\n",
    "        scene = setup_standard_scene(perspective_camera)\n",
    "        scene.add(pyrender.Mesh.from_points(pointcloud, colors=colors), pose=np.eye(4) + translation)\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params.camera_pose + translation)\n",
    "\n",
    "        r = pyrender.OffscreenRenderer(img_width * 2, img_height * 2)\n",
    "        color, depth = r.render(scene)\n",
    "        r.delete()\n",
    "\n",
    "    #     img_with_mask = np.array(img)\n",
    "    #     img_with_mask[depth != 0] = color[depth != 0]\n",
    "        fig = plt.figure(figsize=(8, 12))\n",
    "        plt.imshow(color)\n",
    "        plot_manager.save_current_plot(f\"iteration_{i:05d}.jpg\")\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-montana",
   "metadata": {},
   "source": [
    "## 6.1. Render Optimization Parameters per Step (Sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_manager = PlotManager.new_run(\"3d_sparse_reconstruction/fitting\")\n",
    "store_param_history(plot_manager, sparse_context.get_param_history())\n",
    "plot_manager.generate_video('iteration_', '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-center",
   "metadata": {},
   "source": [
    "## 6.2. Render Optimization Parameters per Step (Dense) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_manager = PlotManager.new_run(\"3d_dense_reconstruction/fitting\")\n",
    "store_param_history(plot_manager, dense_param_history)\n",
    "plot_manager.generate_video('iteration_', '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-eleven",
   "metadata": {},
   "source": [
    "## 6.3. Reconstruction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_manager = PlotManager(\"reconstruction_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_pointcloud=False, show_mask=True)\n",
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "r.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_img = np.abs(depth_img * 1000 - depth)\n",
    "diff_img[depth == 0] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(diff_img)\n",
    "plt.colorbar()\n",
    "plt.clim(0, 50);\n",
    "#plot_manager.save_current_plot(\"combined.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
