{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrender\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import optimize\n",
    "from math import sin, cos\n",
    "from numpy.linalg import det\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.data.iphone import IPhoneDataLoader\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, SimpleImageRenderer, setup_standard_scene, get_perspective_camera, backproject_image\n",
    "from face_reconstruction.optim import BFMOptimization, run_icp, NearestNeighborMode, DistanceType, nearest_neighbors\n",
    "from face_reconstruction.utils.math import add_column, geometric_median\n",
    "from env import PLOTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-wilderness",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(frame_id):\n",
    "    loader = IPhoneDataLoader()\n",
    "    frame = loader.get_frame(frame_id)\n",
    "    img = frame.get_color_image()\n",
    "    depth_img = frame.get_depth_image()\n",
    "    img_width = loader.get_image_width()\n",
    "    img_height = loader.get_image_height()\n",
    "    intrinsics = frame.get_intrinsics()\n",
    "    \n",
    "    depth_threshold = 0.5 # Drop all points behind that threshold\n",
    "    \n",
    "    points = backproject_image(intrinsics, depth_img)\n",
    "    points_to_render = points[:, :3]\n",
    "    points_to_render *= 1000 # meter to millimeter\n",
    "    colors = img.reshape(-1, 3)  # Just flatten color image\n",
    "    \n",
    "    foreground_mask = depth_img.reshape(-1) < depth_threshold\n",
    "    pointcloud = points_to_render[foreground_mask]\n",
    "    colors = colors[foreground_mask]\n",
    "    \n",
    "    return img, depth_img, img_width, img_height, intrinsics, pointcloud, colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-campaign",
   "metadata": {},
   "source": [
    "# 2. Detect 3D landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_3d_landmarks(img, depth_img):\n",
    "    landmarks_img, face_pos = detect_landmarks(img, return_face_pos=True)\n",
    "    face_pos = face_pos[0]\n",
    "    \n",
    "    # Interpolate\n",
    "    interpolation_size = 1\n",
    "    rgb_depth_values = [interpolate_around(depth_img, pixel, interpolation_size) for pixel in landmarks_img]\n",
    "    \n",
    "    landmark_points_3d = backproject_points(intrinsics, rgb_depth_values, landmarks_img)\n",
    "    landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "    landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)if isinstance(loader, IPhoneDataLoader):\n",
    "    landmark_points_3d_render *= 1000  # meter to millimeter\n",
    "    \n",
    "    # It can happen that depth information is bad and back-projected landmark points are far away from the other. These should be ignored\n",
    "    landmark_points_3d_median = geometric_median(landmark_points_3d_render)\n",
    "    distances_from_median = np.linalg.norm(landmark_points_3d_render - landmark_points_3d_median, axis=1)\n",
    "    threshold_landmark_deviation = 500  \n",
    "    valid_landmark_points_3d = np.where((np.array(rgb_depth_values) != 0) & (distances_from_median < threshold_landmark_deviation))[0]\n",
    "    \n",
    "    return face_pos, valid_landmark_points_3d, landmark_points_3d_render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-wilson",
   "metadata": {},
   "source": [
    "## 2.1 Restrict Pointcloud to Facial Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_facial_points(face_pos, depth_img):\n",
    "    face_depth_values = []\n",
    "    face_pixels = []\n",
    "    interpolation_size = 1\n",
    "    \n",
    "    for x in range(face_pos.left(), face_pos.right() + 1):\n",
    "        for y in range(face_pos.top(), face_pos.bottom() + 1):\n",
    "            pixel = [x, y]\n",
    "            face_depth_value = interpolate_around(depth_img, pixel, interpolation_size)\n",
    "            if face_depth_value > 0:\n",
    "                face_depth_values.append(face_depth_value)\n",
    "                face_pixels.append(pixel)\n",
    "                \n",
    "    face_pointcloud = backproject_points(intrinsics, face_depth_values, face_pixels)\n",
    "    face_pointcloud[:, 2] = -face_pointcloud[:, 2]\n",
    "    face_pointcloud_colors = np.array([img[y, x] for x, y in face_pixels])\n",
    "    face_pointcloud *= 1000  # Meters to Millimeters\n",
    "    \n",
    "    body_depth_values = []\n",
    "    body_pixels = []\n",
    "    for x in range(img_width):\n",
    "        for y in range(img_height):\n",
    "            if (x < face_pos.left() or x > face_pos.right()) or (y < face_pos.top() or y > face_pos.bottom()):\n",
    "                pixel = [x, y]\n",
    "                body_depth_value = interpolate_around(depth_img, pixel, interpolation_size)\n",
    "                if body_depth_value > 0:\n",
    "                    body_depth_values.append(body_depth_value)\n",
    "                    body_pixels.append(pixel)\n",
    "                    \n",
    "    body_pointcloud = backproject_points(intrinsics, body_depth_values, body_pixels)\n",
    "    body_pointcloud[:, 2] = -body_pointcloud[:, 2]\n",
    "    body_pointcloud_colors = np.array([img[y, x] for x, y in body_pixels])\n",
    "    body_pointcloud *= 1000  # Meters to Millimetersz\n",
    "    \n",
    "    return face_pointcloud, body_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-stretch",
   "metadata": {},
   "source": [
    "# 3. ICP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-closer",
   "metadata": {},
   "source": [
    "## 3.1 Sparse Recontruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_sparse = 3 # 20\n",
    "n_params_expression_sparse = 3 # 10\n",
    "weight_shape_params_sparse = 100 # 10000\n",
    "weight_expression_params_sparse = 100 # 1000\n",
    "l2_regularization_sparse = 10000  # regularizes only face model parameters\n",
    "rotation_mode = 'lie'\n",
    "\n",
    "sparse_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_sparse,\n",
    "                               n_params_expression=n_params_expression_sparse, \n",
    "                               weight_shape_params=weight_shape_params_sparse, \n",
    "                               weight_expression_params=weight_expression_params_sparse,\n",
    "                               rotation_mode=rotation_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_recon(landmark_points_3d_render):\n",
    "    initial_camera_pose = np.eye(4) # position camera just in front of face\n",
    "\n",
    "    if sparse_optimizer.rotation_mode == 'lie':\n",
    "        theta = 0.0001\n",
    "        initial_camera_pose[:3, :3] = np.array([[1, 0, 0], [0, cos(theta), -sin(theta)], [0, sin(theta), cos(theta)]])\n",
    "        assert abs(det(initial_camera_pose) - 1.0) < 0.00001 \n",
    "\n",
    "    initial_params = sparse_optimizer.create_parameters(\n",
    "        [0 for _ in range(n_shape_coefficients)],\n",
    "        [0 for _ in range(n_expression_coefficients)],\n",
    "        initial_camera_pose\n",
    "    )\n",
    "    \n",
    "    sparse_loss = sparse_optimizer.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d], regularization_strength=l2_regularization_sparse)\n",
    "    sparse_context = sparse_optimizer.create_optimization_context(sparse_loss, initial_params)\n",
    "    result = sparse_context.run_optimization(sparse_loss, initial_params)\n",
    "    \n",
    "    return sparse_context.create_parameters_from_theta(result.x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-scheduling",
   "metadata": {},
   "source": [
    "## 3.2 Dense Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape_dense = 20 # 20\n",
    "n_params_expression_dense = 20 # 10\n",
    "weight_shape_params_dense = 100 # 10000\n",
    "weight_expression_params_dense = 100 # 1000\n",
    "rotation_mode = 'lie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_optimizer = BFMOptimization(bfm, \n",
    "                               n_params_shape=n_params_shape_dense,\n",
    "                               n_params_expression=n_params_expression_dense, \n",
    "                               weight_shape_params=weight_shape_params_dense, \n",
    "                               weight_expression_params=weight_expression_params_dense,\n",
    "                               rotation_mode=rotation_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_recon(face_pointcloud, params_sparse):\n",
    "    nn_mode = NearestNeighborMode.FACE_VERTICES # FACE_VERTICES: every face vertex will be assigned its nearest neighbor in pointcloud\n",
    "                                            # POINTCLOUD: every point in pointcloud will be assigned its nearest neighbor in face model\n",
    "    distance_type = DistanceType.POINT_TO_POINT\n",
    "    icp_iterations = 2\n",
    "    optimization_steps_per_iteration = 20\n",
    "    l2_regularization_dense = 100 # 100\n",
    "    \n",
    "    params, distances, _ = run_icp(dense_optimizer, \n",
    "                               face_pointcloud,\n",
    "                               bfm, \n",
    "                               params_sparse.with_new_manager(dense_optimizer), \n",
    "                               max_iterations=icp_iterations, \n",
    "                               nearest_neighbor_mode=nn_mode, \n",
    "                               distance_type=distance_type,\n",
    "                               max_nfev=optimization_steps_per_iteration,\n",
    "                               l2_regularization=l2_regularization_dense)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-installation",
   "metadata": {},
   "source": [
    "# 4. Render Face Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(params_render, intrinsics, img_width, img_height, pointcloud, colors, show_pointcloud=True, show_mask=True, show_pointcloud_face=False, cut_around_face=4):\n",
    "    \n",
    "    face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params_render.shape_coefficients, \n",
    "        expression_coefficients=params_render.expression_coefficients, \n",
    "        color_coefficients=params_render.color_coefficients)\n",
    "    \n",
    "    bfm_vertices = params_render.camera_pose @ add_column(face_mesh.vertices, 1).T\n",
    "    distances, indices = nearest_neighbors(pointcloud, bfm_vertices[:3, :].T)\n",
    "    pointcloud_mask = distances > cut_around_face\n",
    "    \n",
    "    perspective_camera = get_perspective_camera(intrinsics, img_width, img_height)\n",
    "    scene = setup_standard_scene(perspective_camera)\n",
    "    if show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(pointcloud[pointcloud_mask], colors=colors[pointcloud_mask]), pose=initial_camera_pose)\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params_render.camera_pose)\n",
    "    if not show_pointcloud and show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(face_pointcloud, colors=face_pointcloud_colors), pose=initial_camera_pose)\n",
    "    if show_pointcloud and not show_pointcloud_face:\n",
    "        scene.add(pyrender.Mesh.from_points(body_pointcloud, colors=body_pointcloud_colors), pose=initial_camera_pose)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_img(scene, width, height):\n",
    "    r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "    color, depth = r.render(scene)\n",
    "    r.delete()\n",
    "    img_with_mask = np.array(img)\n",
    "    img_with_mask[depth != 0] = color[depth != 0]\n",
    "    return img_with_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-ownership",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(116)):\n",
    "    img, depth_img, img_width, img_height, intrinsics, pointcloud, colors = get_data(i)\n",
    "    face_pos, valid_landmark_points_3d, landmark_points_3d_render = detect_3d_landmarks(img, depth_img)\n",
    "    face_pointcloud, body_pointcloud = extract_facial_points(face_pos, depth_img)\n",
    "    params_sparse = sparse_recon(landmark_points_3d_render)\n",
    "    params_render = dense_recon(face_pointcloud, params_sparse)\n",
    "    \n",
    "    scene = setup_scene(params_render, intrinsics, img_width, img_height, pointcloud, colors, show_pointcloud=False, show_mask=True)\n",
    "    img = render_img(scene, img_width, img_height) \n",
    "    \n",
    "    img_path = os.path.join(PLOTS_PATH, f'marc_{i:03d}.jpg')\n",
    "    plt.imsave(img_path, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
