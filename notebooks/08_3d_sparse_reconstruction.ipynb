{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corresponding-superior",
   "metadata": {},
   "source": [
    "# 3D Sparse Reconstruction\n",
    "This notebook showcases how sparse face reconstruction with the Basel Face Model can be done directly in 3D.  \n",
    "The resulting optimization problem is simpler as it does not contain projecting between 3D and 2D. However, more preprocessing is necessary.  \n",
    "We need RGB-D data to be able to generate a pointcloud. In this notebook, the `BIWI Kinect Dataset` is used. It can be downloaded here: https://www.kaggle.com/kmader/biwi-kinect-head-pose-database  \n",
    "As depth and color channel typically are not aligned, we first have to do registration.  \n",
    "Finally, we can detect the landmarks in the 2D color image, project them with the depth information to 3D and then proceed with the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrender\n",
    "from scipy import optimize\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.data.iphone import IPhoneDataLoader\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, get_perspective_camera, setup_standard_scene, backproject_image\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.optim import BFMOptimization\n",
    "from face_reconstruction.utils.math import geometric_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-exemption",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-birthday",
   "metadata": {},
   "source": [
    "# 2. Input RGB-D Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "frame_id = 4\n",
    "\n",
    "#loader = BiwiDataLoader(run_id)\n",
    "loader = IPhoneDataLoader()\n",
    "frame = loader.get_frame(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = loader.get_image_width()\n",
    "img_height = loader.get_image_height()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.get_color_image()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_img = frame.get_depth_image()\n",
    "plt.imshow(depth_img)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-tolerance",
   "metadata": {},
   "source": [
    "## 2.1 Depth and RGB channels are not aligned (only BIWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_color_image = frame.get_color_image()\n",
    "masked_color_image[frame.get_depth_image() == 0] = 0\n",
    "plt.imshow(masked_color_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-fifth",
   "metadata": {},
   "source": [
    "## 2.2 Align Depth and RGB channels (Registration, only BIWI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, colors, screen_positions = register_rgb_depth(frame.get_depth_image(), frame.get_color_image(), biwi_loader.get_depth_intrinsics(), biwi_loader.get_rgb_intrinsics(), biwi_loader.get_rgb_extrinsics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_depth_mask = np.zeros((img_height, img_width))\n",
    "draw_pixels_to_image(img_depth_mask, screen_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_color_image = frame.get_color_image()\n",
    "masked_color_image[img_depth_mask == 0] = 0\n",
    "plt.imshow(masked_color_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-footage",
   "metadata": {},
   "source": [
    "# 3. Render Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    depth_threshold = 0.5 # Drop all points behind that threshold\n",
    "    \n",
    "    intrinsics = frame.get_intrinsics()\n",
    "    points = backproject_image(intrinsics, depth_img)\n",
    "    points_to_render = points[:, :3]\n",
    "    points_to_render[:,2] = -points[:, 2]  # Invert z-coordinate\n",
    "    points_to_render *= 1000 # meter to millimeter\n",
    "    colors = img.reshape(-1, 3)  # Just flatten color image\n",
    "    \n",
    "    foreground_mask = depth_img.reshape(-1) < depth_threshold\n",
    "    points_to_render = points_to_render[foreground_mask]\n",
    "    colors = colors[foreground_mask]\n",
    "else:\n",
    "    intrinsics = loader.get_rgb_intrinsics()\n",
    "    points_to_render = np.array(points)\n",
    "    points_to_render[:, 2] = -points_to_render[:, 2]  # Invert z-coordinate for easier rendering (point cloud will be right in front of camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_camera = get_perspective_camera(intrinsics, img_width, img_height)\n",
    "scene = setup_standard_scene(perspective_camera)\n",
    "scene.add(pyrender.Mesh.from_points(points_to_render, colors=colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-slide",
   "metadata": {},
   "source": [
    "# 4. Detect 3D Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_img = detect_landmarks(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    rgb_depth_img = depth_img\n",
    "else:\n",
    "    # Create a depth image for easier querying of depth values\n",
    "    rgb_depth_img = np.zeros((img_height, img_width))\n",
    "    for point, screen_position in zip(points, screen_positions):\n",
    "        rgb_depth_img[screen_position[1], screen_position[0]] = point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As RGB and depth channels are not aligned, we might not have exact depth information for every pixel in the color channel. Hence, we have to interpolate\n",
    "interpolation_size = 1\n",
    "rgb_depth_values = [interpolate_around(rgb_depth_img, pixel, interpolation_size) for pixel in landmarks_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d = backproject_points(intrinsics, rgb_depth_values, landmarks_img)\n",
    "landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)\n",
    "if isinstance(loader, IPhoneDataLoader):\n",
    "    landmark_points_3d_render *= 1000  # meter to millimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d_median = geometric_median(landmark_points_3d_render)\n",
    "distances_from_median = np.linalg.norm(landmark_points_3d_render - landmark_points_3d_median, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_landmark_deviation = 500  # It can happen that depth information is bad and back-projected landmark points are far away from the other. These should be ignored\n",
    "valid_landmark_points_3d = np.where((np.array(rgb_depth_values) != 0) & (distances_from_median < threshold_landmark_deviation))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_without_depth = 68 - len(valid_landmark_points_3d)\n",
    "if pixels_without_depth > 0:\n",
    "    print(f\"There are {pixels_without_depth} pixels without depth information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_standard_scene(perspective_camera)\n",
    "scene.add(pyrender.Mesh.from_points(points_to_render, colors=colors))\n",
    "scene.add(pyrender.Mesh.from_points(landmark_points_3d_render[valid_landmark_points_3d], colors=[[255, 0, 0] for _ in range(len(landmark_points_3d[valid_landmark_points_3d]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-fairy",
   "metadata": {},
   "source": [
    "# 5. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape = 3 # 20\n",
    "n_params_expression = 3 # 10\n",
    "weight_shape_params = 100 # 10000\n",
    "weight_expression_params = 100 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_optimization = BFMOptimization(bfm, n_params_shape, n_params_expression, weight_shape_params=weight_shape_params, weight_expression_params=weight_expression_params)\n",
    "loss = sparse_optimization.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_camera_pose = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, -500], [0, 0, 0, 1]]) # position camera just in front of face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = sparse_optimization.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This typically takes 20 seconds\n",
    "sparse_context = sparse_optimization.create_optimization_context(loss, initial_params, max_nfev=100, verbose=2, x_scale='jac')\n",
    "result = sparse_context.run_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-intensity",
   "metadata": {},
   "source": [
    "# 6. Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sparse_context.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params.shape_coefficients, \n",
    "        expression_coefficients=params.expression_coefficients, \n",
    "        color_coefficients=[0 for _ in range(n_color_coefficients)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm_landmark_vertices = np.array(face_mesh.vertices)[bfm_landmark_indices[valid_landmark_points_3d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(show_landmarks=True, show_pointcloud=True, show_mask=True):\n",
    "    scene = setup_standard_scene(perspective_camera)\n",
    "    if show_pointcloud:\n",
    "        scene.add(pyrender.Mesh.from_points(points_to_render, colors=colors))\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params.camera_pose)\n",
    "    if show_landmarks:\n",
    "        scene.add(pyrender.Mesh.from_points(landmark_points_3d_render[valid_landmark_points_3d], colors=[[255, 0, 0] for _ in range(len(landmark_points_3d[valid_landmark_points_3d]))]))\n",
    "        scene.add(pyrender.Mesh.from_points(bfm_landmark_vertices, colors=[[0, 255, 0] for _ in range(len(bfm_landmark_vertices))]), pose=params.camera_pose)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-granny",
   "metadata": {},
   "source": [
    "## 6.1. Render Interactive 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_landmarks=True, show_pointcloud=True, show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-brave",
   "metadata": {},
   "source": [
    "## 6.2. Render onto Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_landmarks=False, show_pointcloud=False, show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "r.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_mask = np.array(img)\n",
    "img_with_mask[depth != 0] = color[depth != 0]\n",
    "plt.imshow(img_with_mask)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
