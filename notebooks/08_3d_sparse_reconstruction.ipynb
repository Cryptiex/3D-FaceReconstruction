{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "existing-regular",
   "metadata": {},
   "source": [
    "# 3D Sparse Reconstruction\n",
    "This notebook showcases how sparse face reconstruction with the Basel Face Model can be done directly in 3D.  \n",
    "The resulting optimization problem is simpler as it does not contain projecting between 3D and 2D. However, more preprocessing is necessary.  \n",
    "We need RGB-D data to be able to generate a pointcloud. In this notebook, the `BIWI Kinect Dataset` is used. It can be downloaded here: https://www.kaggle.com/kmader/biwi-kinect-head-pose-database  \n",
    "As depth and color channel typically are not aligned, we first have to do registration.  \n",
    "Finally, we can detect the landmarks in the 2D color image, project them with the depth information to 3D and then proceed with the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrender\n",
    "from scipy import optimize\n",
    "\n",
    "from face_reconstruction.data.biwi import BiwiDataLoader\n",
    "from face_reconstruction.graphics import draw_pixels_to_image, register_rgb_depth, backproject_points, interpolate_around, get_perspective_camera, setup_standard_scene\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.optim import BFMOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-berkeley",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = np.array(list(bfm_landmarks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-storm",
   "metadata": {},
   "source": [
    "# 2. Input RGB-D Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 1\n",
    "frame_id = 4\n",
    "\n",
    "biwi_loader = BiwiDataLoader(run_id)\n",
    "frame = biwi_loader.get_frame(frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = biwi_loader.get_image_width()\n",
    "img_height = biwi_loader.get_image_height()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame.get_color_image()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame.get_depth_image())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-diploma",
   "metadata": {},
   "source": [
    "## 2.1 Depth and RGB channels are not aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_color_image = frame.get_color_image()\n",
    "masked_color_image[frame.get_depth_image() == 0] = 0\n",
    "plt.imshow(masked_color_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-scratch",
   "metadata": {},
   "source": [
    "## 2.2 Align Depth and RGB channels (Registration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, colors, screen_positions = register_rgb_depth(frame.get_depth_image(), frame.get_color_image(), biwi_loader.get_depth_intrinsics(), biwi_loader.get_rgb_intrinsics(), biwi_loader.get_rgb_extrinsics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_depth_mask = np.zeros((img_height, img_width))\n",
    "draw_pixels_to_image(img_depth_mask, screen_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_color_image = frame.get_color_image()\n",
    "masked_color_image[img_depth_mask == 0] = 0\n",
    "plt.imshow(masked_color_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-attack",
   "metadata": {},
   "source": [
    "# 3. Render Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_camera = get_perspective_camera(biwi_loader.get_rgb_intrinsics(), img_width, img_height)\n",
    "scene = setup_standard_scene(perspective_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_render = np.array(points)\n",
    "points_to_render[:, 2] = -points_to_render[:, 2]  # Invert z-coordinate for easier rendering (point cloud will be right in front of camera)\n",
    "scene.add(pyrender.Mesh.from_points(points_to_render, colors=colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-detection",
   "metadata": {},
   "source": [
    "# 4. Detect 3D Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_img = detect_landmarks(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a depth image for easier querying of depth values\n",
    "rgb_depth_img = np.zeros((img_height, img_width))\n",
    "for point, screen_position in zip(points, screen_positions):\n",
    "    rgb_depth_img[screen_position[1], screen_position[0]] = point[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As RGB and depth channels are not aligned, we might not have exact depth information for every pixel in the color channel. Hence, we have to interpolate\n",
    "interpolation_size = 1\n",
    "rgb_depth_values = [interpolate_around(rgb_depth_img, pixel, interpolation_size) for pixel in landmarks_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_without_depth = sum(np.array(rgb_depth_values) == 0)\n",
    "if pixels_without_depth > 0:\n",
    "    print(f\"There are {pixels_without_depth} pixels without depth information. Consider increasing `interpolation_size`!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_landmark_points_3d = np.where(np.array(rgb_depth_values) != 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_points_3d = backproject_points(biwi_loader.get_rgb_intrinsics(), rgb_depth_values, landmarks_img)\n",
    "landmark_points_3d_render = np.array(landmark_points_3d)\n",
    "landmark_points_3d_render[:,2] = -landmark_points_3d_render[:,2]  # Invert z-coordinate for easier rendering (landmarks will be right in front of camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_standard_scene(perspective_camera)\n",
    "scene.add(pyrender.Mesh.from_points(points_to_render, colors=colors))\n",
    "scene.add(pyrender.Mesh.from_points(landmark_points_3d_render[valid_landmark_points_3d], colors=[[255, 0, 0] for _ in range(len(landmark_points_3d[valid_landmark_points_3d]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-spine",
   "metadata": {},
   "source": [
    "# 5. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape = 3 # 20\n",
    "n_params_expression = 3 # 10\n",
    "weight_shape_params = 1 # 10000\n",
    "weight_expression_params = 1 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_optimization = BFMOptimization(bfm, n_params_shape, n_params_expression, weight_shape_params=weight_shape_params, weight_expression_params=weight_expression_params)\n",
    "loss = sparse_optimization.create_sparse_loss_3d(bfm_landmark_indices[valid_landmark_points_3d], landmark_points_3d_render[valid_landmark_points_3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_camera_pose = np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = sparse_optimization.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This typically takes 20 seconds\n",
    "result = optimize.least_squares(loss, initial_params.to_theta(), max_nfev=100, verbose=2, x_scale='jac')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-glass",
   "metadata": {},
   "source": [
    "# 6. Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sparse_optimization.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params.shape_coefficients, \n",
    "        expression_coefficients=params.expression_coefficients, \n",
    "        color_coefficients=[0 for _ in range(n_color_coefficients)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm_landmark_vertices = np.array(face_mesh.vertices)[bfm_landmark_indices[valid_landmark_points_3d]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scene(show_landmarks=True, show_pointcloud=True, show_mask=True):\n",
    "    scene = setup_standard_scene(perspective_camera)\n",
    "    if show_pointcloud:\n",
    "        scene.add(pyrender.Mesh.from_points(points_to_render, colors=colors), pose=initial_camera_pose)\n",
    "    if show_mask:\n",
    "        scene.add(pyrender.Mesh.from_trimesh(bfm.convert_to_trimesh(face_mesh)), pose=params.camera_pose)\n",
    "    if show_landmarks:\n",
    "        scene.add(pyrender.Mesh.from_points(landmark_points_3d_render[valid_landmark_points_3d], colors=[[255, 0, 0] for _ in range(len(landmark_points_3d[valid_landmark_points_3d]))]), pose=initial_camera_pose)\n",
    "        scene.add(pyrender.Mesh.from_points(bfm_landmark_vertices, colors=[[0, 255, 0] for _ in range(len(bfm_landmark_vertices))]), pose=params.camera_pose)\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-tucson",
   "metadata": {},
   "source": [
    "## 6.1. Render Interactive 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_landmarks=True, show_pointcloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-equilibrium",
   "metadata": {},
   "source": [
    "## 6.2. Render onto Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = setup_scene(show_landmarks=False, show_pointcloud=False, show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "r.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_mask = np.array(img)\n",
    "img_with_mask[depth != 0] = color[depth != 0]\n",
    "plt.imshow(img_with_mask)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
