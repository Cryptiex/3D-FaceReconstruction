{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrender\n",
    "from scipy import optimize\n",
    "\n",
    "from env import DATA_PATH\n",
    "from face_reconstruction.graphics import SimpleImageRenderer, draw_pixels_to_image, cv2_to_plt\n",
    "from face_reconstruction.landmarks import load_bfm_landmarks, detect_landmarks\n",
    "from face_reconstruction.model import BaselFaceModel\n",
    "from face_reconstruction.optim import SparseOptimization\n",
    "from face_reconstruction.plots import PlotManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfm = BaselFaceModel.from_h5(\"model2019_face12.h5\")\n",
    "bfm_landmarks = load_bfm_landmarks(\"model2019_face12_landmarks_v2\")\n",
    "bfm_landmark_indices = list(bfm_landmarks.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shape_coefficients = bfm.get_n_shape_coefficients()\n",
    "n_expression_coefficients = bfm.get_n_expression_coefficients()\n",
    "n_color_coefficients = bfm.get_n_color_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"trump.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = f\"{DATA_PATH}/Keypoint Detection/{img_name}\"\n",
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_img = detect_landmarks(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = img.shape[1]\n",
    "img_height = img.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup rendering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
    "projection_matrix = perspective_camera.get_projection_matrix(width=img_width, height=img_height)\n",
    "initial_camera_pose = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, -300], [0, 0, 0, 1]]) # position camera just in front of face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = SimpleImageRenderer(projection_matrix, img_width, img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Joint optimization for face parameters and pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Setup Joint Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_shape = 20 # 20\n",
    "n_params_expression = 10 # 10\n",
    "weight_shape_params = 10000 # 10000\n",
    "weight_expression_params = 1000 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_optimization = SparseOptimization(bfm, n_params_shape, n_params_expression, weight_shape_params=weight_shape_params, weight_expression_params=weight_expression_params)\n",
    "loss = sparse_optimization.create_loss(renderer, bfm_landmark_indices, landmarks_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = sparse_optimization.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(sparse_optimization.create_parameters_from_theta(initial_params.to_theta()).to_theta() == initial_params.to_theta()), \"OptimizationParameters is ill-defined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params.to_theta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Run Joint Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This typically takes 20 seconds\n",
    "result = optimize.least_squares(loss, initial_params.to_theta(), max_nfev=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found parameters\n",
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cost\n",
    "result.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sparse_optimization.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2. Alternating Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1. Setup Alternating Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations_face = 2 * (n_params_shape + n_params_expression)\n",
    "n_iterations_camera = 20\n",
    "n_dual_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_optimizer = SparseOptimization(bfm, n_params_shape, n_params_expression, fix_camera_pose=True, weight_shape_params=weight_shape_params, weight_expression_params=weight_expression_params)\n",
    "camera_optimizer = SparseOptimization(bfm, 0, 0, fix_camera_pose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = face_optimizer.create_parameters(\n",
    "    [0 for _ in range(n_shape_coefficients)],\n",
    "    [0 for _ in range(n_expression_coefficients)],\n",
    "    initial_camera_pose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_optimizer_loss = face_optimizer.create_loss(renderer, bfm_landmark_indices, landmarks_img, fixed_camera_pose=initial_camera_pose)\n",
    "camera_optimizer_loss = camera_optimizer.create_loss(renderer, bfm_landmark_indices, landmarks_img, fixed_shape_coefficients=initial_params.shape_coefficients, fixed_expression_coefficients=initial_params.expression_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Run Alternating Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(n_dual_iterations):\n",
    "    camera_optimizer_loss = camera_optimizer.create_loss(renderer, bfm_landmark_indices, landmarks_img, fixed_shape_coefficients=params.shape_coefficients, fixed_expression_coefficients=params.expression_coefficients)\n",
    "    params = camera_optimizer.create_parameters(camera_pose=face_optimizer_loss.fixed_camera_pose)\n",
    "    result = optimize.least_squares(camera_optimizer_loss, params.to_theta(), max_nfev=n_iterations_camera, verbose=2)\n",
    "    print(result.cost)\n",
    "    params = camera_optimizer.create_parameters_from_theta(result.x)\n",
    "    \n",
    "    face_optimizer_loss = face_optimizer.create_loss(renderer, bfm_landmark_indices, landmarks_img, fixed_camera_pose=params.camera_pose)\n",
    "    params = face_optimizer.create_parameters(shape_coefficients=camera_optimizer_loss.fixed_shape_coefficients, expression_coefficients=camera_optimizer_loss.fixed_expression_coefficients)\n",
    "    result = optimize.least_squares(face_optimizer_loss, params.to_theta(), max_nfev=n_iterations_face, verbose=2)\n",
    "    print(result.cost)\n",
    "    params = face_optimizer.create_parameters_from_theta(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_dual = [3.2807e+05, 4.8681e+04, 3.9522e+04, 8.1128e+03, 5.9347e+03, 3.2546e+03, 3.1953e+03, 3.1863e+03, 3.1856e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 3.1855e+03, 4.0271e+02, 3.8531e+02, 3.7645e+02, 3.7607e+02, 3.7505e+02, 3.7504e+02, 3.7504e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.7503e+02, 3.5441e+02, 3.5427e+02, 3.5424e+02, 3.5423e+02, 3.5423e+02, 3.5423e+02, 3.5423e+02, 3.5423e+02, 3.5423e+02, 3.5423e+02, 3.5423e+02, 3.4254e+02, 3.3994e+02, 3.3827e+02, 3.3746e+02, 3.3719e+02, 3.3695e+02, 3.3687e+02, 3.3684e+02, 3.3683e+02, 3.3683e+02, 3.3682e+02, 3.3682e+02, 3.3682e+02, 3.3682e+02, 3.3682e+02, 3.3682e+02, 3.3089e+02, 3.2987e+02, 3.2927e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2926e+02, 3.2420e+02, 3.2355e+02, 3.2353e+02, 3.2353e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.2352e+02, 3.1899e+02, 3.1864e+02, 3.1860e+02, 3.1857e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1856e+02, 3.1630e+02, 3.1606e+02, 3.1591e+02, 3.1586e+02, 3.1584e+02, 3.1583e+02, 3.1583e+02, 3.1583e+02, 3.1583e+02, 3.1583e+02, 3.1583e+02, 3.1583e+02, 3.1292e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.1290e+02, 3.0767e+02, 3.0446e+02, 3.0440e+02, 3.0427e+02, 3.0425e+02, 3.0424e+02, 3.0424e+02, 3.0423e+02, 3.0423e+02, 3.0423e+02, 3.0423e+02, 3.0423e+02, 3.0087e+02, 3.0081e+02, 3.0081e+02, 3.0081e+02, 3.0081e+02, 3.0081e+02, 3.0081e+02, 3.0081e+02, 3.0081e+02, 2.9878e+02, 2.9860e+02, 2.9854e+02, 2.9851e+02, 2.9850e+02, 2.9849e+02, 2.9848e+02, 2.9847e+02, 2.9847e+02, 2.9847e+02, 2.9847e+02, 2.9847e+02, 2.9847e+02, 2.9847e+02, 2.9847e+02, 2.9613e+02, 2.9613e+02, 2.9613e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9612e+02, 2.9300e+02, 2.9265e+02, 2.9253e+02, 2.9250e+02, 2.9249e+02, 2.9248e+02, 2.9248e+02, 2.9248e+02, 2.9248e+02, 2.9248e+02, 2.9248e+02, 2.9248e+02, 2.9248e+02, 2.9018e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.9017e+02, 2.8814e+02, 2.8810e+02, 2.8800e+02, 2.8799e+02, 2.8798e+02, 2.8798e+02, 2.8798e+02, 2.8798e+02, 2.8798e+02, 2.8798e+02, 2.8631e+02, 2.8599e+02, 2.8596e+02, 2.8596e+02, 2.8596e+02, 2.8596e+02, 2.8596e+02, 2.8596e+02, 2.8596e+02, 2.8488e+02, 2.8433e+02, 2.8430e+02, 2.8427e+02, 2.8426e+02, 2.8426e+02, 2.8426e+02, 2.8426e+02, 2.8426e+02, 2.8426e+02, 2.8426e+02, 2.8426e+02, 2.8253e+02, 2.8252e+02, 2.8252e+02, 2.8252e+02, 2.8252e+02, 2.8252e+02, 2.8252e+02, 2.8252e+02, 2.8168e+02, 2.8125e+02, 2.8119e+02, 2.8114e+02, 2.8111e+02, 2.8110e+02, 2.8109e+02, 2.8109e+02, 2.8109e+02, 2.8109e+02, 2.8109e+02]\n",
    "costs_joint = [3.2807e+05, 4.3899e+04, 2.0022e+04, 1.9179e+03, 7.7233e+02, 4.3539e+02, 3.6307e+02, 2.9366e+02, 2.5590e+02, 2.5270e+02, 2.5069e+02, 2.5013e+02, 2.4999e+02, 2.4998e+02, 2.4996e+02]\n",
    "plt.title(\"Joint vs Alternating Optimization\")\n",
    "plt.plot(costs_dual[20:], label='Alternating Optimization')\n",
    "plt.plot(costs_joint[5:], label='Joint Optimization')\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_optimization = SparseOptimization(bfm, n_params_shape, n_params_expression, weight_shape_params=weight_shape_params, weight_expression_params=weight_expression_params)\n",
    "params = sparse_optimization.create_parameters(shape_coefficients=params.shape_coefficients, expression_coefficients=params.expression_coefficients, camera_pose=face_optimizer_loss.fixed_camera_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Draw mask on input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_manager = PlotManager(\"sparse_reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_mesh = bfm.draw_sample(\n",
    "        shape_coefficients=params.shape_coefficients, \n",
    "        expression_coefficients=params.expression_coefficients, \n",
    "        color_coefficients=[0 for _ in range(n_color_coefficients)])\n",
    "face_pixels = renderer.project_points(params.camera_pose, face_mesh.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "img = cv2_to_plt(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_bfm_landmarks = renderer.project_points(params.camera_pose, np.array(face_mesh.vertices)[bfm_landmark_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_pixels_to_image(img, face_pixels, color=1)\n",
    "draw_pixels_to_image(img, landmarks_img, color=[0, 255, 0])\n",
    "draw_pixels_to_image(img, pixels_bfm_landmarks, color=[255, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 14))\n",
    "plt.imshow(img)\n",
    "plot_manager.save_current_plot(f\"landmarks_fitting_{img_name}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Render full mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=img_width / img_height)\n",
    "directional_light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_trimesh = bfm.convert_to_trimesh(face_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = pyrender.Scene()\n",
    "scene.add(pyrender.Mesh.from_trimesh(face_trimesh), pose=params.camera_pose)\n",
    "scene.add(perspective_camera)\n",
    "scene.add(directional_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Interactive rendering (face only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrender.Viewer(scene, use_raymond_lighting=True, viewport_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Render face onto input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "\n",
    "color, depth = r.render(scene)\n",
    "r.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_mask = depth != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "img = cv2_to_plt(img)\n",
    "img[depth_mask] = color[depth_mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(img_width / 50, img_height / 50))\n",
    "plt.imshow(img)\n",
    "plot_manager.save_current_plot(f\"mask_fitting_{img_name}.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
